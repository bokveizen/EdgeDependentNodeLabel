{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42bd6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db64c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = \"emailEnron_0\"\n",
    "ep=100\n",
    "labelnum = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d824d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_confusion_matrices(dirpath, fname=\"log_test_confusion.txt\", ep=10, labelnum=3):\n",
    "    if os.path.isfile(dirpath + \"log_valid_confusion.txt\") is True:\n",
    "        fname = \"log_valid_confusion.txt\"\n",
    "        evalname = \"valid\"\n",
    "    else:\n",
    "        evalname = \"test\"\n",
    "        \n",
    "    if os.path.isfile(dirpath + fname) is False:\n",
    "        # print(\"not exist\", dirpath + fname)\n",
    "        return -1\n",
    "    if os.path.isfile(dirpath + \"log_{}_micro.txt\".format(evalname)):\n",
    "        num_epoch = 0\n",
    "        num_times = 0\n",
    "        best_f1 = 0\n",
    "        total_epoch = 0\n",
    "        with open(dirpath + \"log_{}_micro.txt\".format(evalname), \"r\") as f:\n",
    "            for i, line in enumerate(f.readlines()):\n",
    "                ep_str = line.rstrip().split(\":\")[0]\n",
    "                f1_str = line.rstrip().split(\":\")[-1]\n",
    "                epoch = int(ep_str.split(\" \")[0])\n",
    "                f1 = float(f1_str)\n",
    "                if best_f1 < f1:\n",
    "                    num_epoch = epoch\n",
    "                    num_times = i + 1\n",
    "                    best_f1 = f1\n",
    "                else:\n",
    "                    total_epoch = epoch\n",
    "    else:\n",
    "        best_f1 = 0\n",
    "        num_epoch = ep\n",
    "        total_epoch = ep\n",
    "        num_times = 1\n",
    "            \n",
    "    with open(dirpath + fname, \"r\") as f:\n",
    "        one_input = []\n",
    "        for line in f.readlines():\n",
    "            if len(one_input) == labelnum:\n",
    "                num_times -= 1\n",
    "                if num_times == 0:\n",
    "                    break\n",
    "                one_input = []\n",
    "            one_input.append(line)\n",
    "                \n",
    "    confusion_matrix = np.zeros((labelnum,labelnum))\n",
    "    for i in range(labelnum):\n",
    "        line = one_input[i].rstrip()\n",
    "        tmp = line.split(\"\\t\")\n",
    "        for c, v in enumerate(tmp):\n",
    "            confusion_matrix[i,c] = int(v)\n",
    "\n",
    "    accuracy = sum([confusion_matrix[i, i] for i in range(labelnum)]) / (np.sum(confusion_matrix))\n",
    "    \n",
    "    rec_bar = []\n",
    "    label_num = []\n",
    "    recall_micro_denom = 0\n",
    "    recall_micro_numer = 0\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        row_sum = np.sum(confusion_matrix[i])\n",
    "        label_num.append(row_sum)\n",
    "        ans = confusion_matrix[i,i]\n",
    "        if row_sum == 0:\n",
    "            rec_bar.append(0)\n",
    "        else:\n",
    "            rec_bar.append(ans / row_sum)\n",
    "        recall_micro_denom += row_sum\n",
    "        recall_micro_numer += ans\n",
    "    \n",
    "    recall_macro = sum(rec_bar) / labelnum\n",
    "    recall_micro = recall_micro_numer / recall_micro_denom\n",
    "    \n",
    "    prec_bar = []\n",
    "    pred_label_num = []\n",
    "    precision_micro_denom = 0\n",
    "    precision_micro_numer = 0\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        col_sum = np.sum(confusion_matrix[:,i])\n",
    "        pred_label_num.append(col_sum)\n",
    "        ans = confusion_matrix[i,i]\n",
    "        if col_sum == 0:\n",
    "            prec_bar.append(0)\n",
    "        else:\n",
    "            prec_bar.append(ans / col_sum)\n",
    "        precision_micro_denom += col_sum\n",
    "        precision_micro_numer += ans\n",
    "    precision_macro = sum(prec_bar) / labelnum\n",
    "    precision_micro = precision_micro_numer / precision_micro_denom\n",
    "    \n",
    "    f1_bar = []\n",
    "    for i in range(len(rec_bar)):\n",
    "        if (prec_bar[i] + rec_bar[i]) == 0:\n",
    "            f1_bar.append(0)\n",
    "        else:\n",
    "            f1_bar.append(2 * ( (prec_bar[i] * rec_bar[i]) / (prec_bar[i] + rec_bar[i]) ))\n",
    "    f1score_macro = sum(f1_bar) / labelnum\n",
    "    f1score_micro = 2 * ( (precision_micro * recall_micro) / (precision_micro + recall_micro))\n",
    "    \n",
    "    if f1score_macro == 1.00:\n",
    "        print(confusion_matrix)\n",
    "        print(rec_bar)\n",
    "        print(prec_bar)\n",
    "        print(f1_bar)\n",
    "        print(dirpath)\n",
    "    assert best_f1 == 0 or best_f1 == f1score_micro, dirpath + \"\\t\" + str(best_f1) + \" \" + str(f1score_micro)\n",
    "    \n",
    "    # Label Diff\n",
    "    numlabelrate = []\n",
    "    total_label_ratio = 0\n",
    "    all_labels = sum(label_num)\n",
    "    for i in range(labelnum):\n",
    "        numlabelrate.append((abs(pred_label_num[i] - label_num[i]) / label_num[i])) # pred_label_num[i] / label_num[i]) # distance??\n",
    "        total_label_ratio += (abs(pred_label_num[i] - label_num[i]) / label_num[i]) * (label_num[i] / all_labels)\n",
    "#         numlabelrate.append(1.0 - (abs(pred_label_num[i] - label_num[i]) / label_num[i])) # pred_label_num[i] / label_num[i]) # distance??\n",
    "#         total_label_ratio += (abs(pred_label_num[i] - label_num[i]) / label_num[i])\n",
    "    \n",
    "    \n",
    "    result = {\n",
    "        \"accuracy\" : accuracy,\n",
    "        \"f1_micro\": f1score_micro,\n",
    "        \"f1_macro\": f1score_macro,\n",
    "        \"num_epoch\" : num_epoch,\n",
    "        \"total_epoch\" : total_epoch,\n",
    "        \"labeldiff\" : total_label_ratio,\n",
    "    }\n",
    "    for i in range(labelnum):\n",
    "        result[\"recall_\" + str(i)] = rec_bar[i]\n",
    "        result[\"precision_\" + str(i)] = prec_bar[i]\n",
    "        result[\"f1_\" + str(i)] = f1_bar[i]\n",
    "        result[\"labelratio_\" + str(i)] = numlabelrate[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4db438",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdict = defaultdict(dict)\n",
    "model2bestparam = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ed0c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results_v2/emailEnron_0/rw/transformer-RankAdd-PrevQ-RankAdd-PrevQ_atnl1_nl1_sm_snl1/hd_64_od_128_bs_64_lr_0.001_ni_4_sp_40/\n"
     ]
    }
   ],
   "source": [
    "# Add F1 macro\n",
    "for initvec in [\"rw\"]: # \"onehot\", \"adj\",\n",
    "    orgdir = \"../results_v2/\" + dataname + \"/\" + initvec + \"/\"\n",
    "    \n",
    "    refined_list = defaultdict(list)\n",
    "    for modelname in os.listdir(orgdir):\n",
    "        modelnamedir = orgdir + modelname + \"/\"\n",
    "#         print(modelnamedir)\n",
    "        if \"past\" in modelname:\n",
    "            continue\n",
    "        if os.path.isdir(modelnamedir) is False:\n",
    "            continue\n",
    "        embedder = modelname.split(\"_\")[0]\n",
    "        if len(embedder.split(\"-\")) > 1:\n",
    "            _, attV, aggV, attE, aggE = embedder.split(\"-\")\n",
    "            if attE != \"pure\" and aggE == \"PrevQ\": # Common Condition!\n",
    "                refined_list[embedder].append(modelnamedir)\n",
    "    \n",
    "    model2param = defaultdict(dict)\n",
    "    for modelname in refined_list:\n",
    "        for modelnamedir in refined_list[modelname]: # number of layer\n",
    "#             print(modelnamedir)\n",
    "            for paramname in os.listdir(modelnamedir): # parameters   \n",
    "                # get Result\n",
    "                paramnamedir = modelnamedir + paramname + \"/\"\n",
    "                if os.path.isdir(paramnamedir) is False:\n",
    "                    continue\n",
    "                res = read_confusion_matrices(paramnamedir, labelnum=labelnum)\n",
    "                if res != -1:\n",
    "                    print(paramnamedir)\n",
    "                    if modelname not in model2param:\n",
    "                        model2param[modelname] = {}\n",
    "                    f1 = (res[\"f1_micro\"] + res[\"f1_macro\"]) / 2\n",
    "                    if abs(res[\"f1_micro\"]-res[\"f1_macro\"]) > 0.2:\n",
    "                        continue\n",
    "                    if paramnamedir not in model2param[modelname]:\n",
    "                        model2param[modelname][paramnamedir] = f1\n",
    "                    elif model2param[modelname][paramnamedir] < f1:\n",
    "                        model2param[modelname][paramnamedir] = f1\n",
    "\n",
    "    for modelname in model2param.keys():\n",
    "        param2f1 = model2param[modelname]\n",
    "        if len(param2f1) == 0:\n",
    "            print(modelname_w_param)\n",
    "            continue\n",
    "        sorted_param = sorted(list(param2f1.keys()), key=lambda x: param2f1[x], reverse=True)\n",
    "        for paramkey in sorted_param:\n",
    "            res = read_confusion_matrices(paramkey, ep=ep, labelnum=labelnum)\n",
    "            if res != -1:\n",
    "                res[\"searchspace\"] = len(param2f1)\n",
    "                \n",
    "                paramname = paramkey.split(\"/\")[-2]\n",
    "                pe = \"-\"\n",
    "                if paramname.split(\"_\")[-2] == \"pe\":\n",
    "                    pe = paramname.split(\"_\")[-1]\n",
    "                res[\"pe\"] = pe\n",
    "                \n",
    "                modeldir = paramkey.split(\"/\")[-3]\n",
    "                _, atnl, nl, _, _ = modeldir.split(\"_\")\n",
    "                atnl = int(atnl[-1])\n",
    "                res[\"atnl\"] = atnl\n",
    "                \n",
    "                \n",
    "                \n",
    "                if modelname not in resultdict:\n",
    "                    resultdict[modelname] = res\n",
    "                    model2bestparam[modelname] = paramkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4371e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'transformer-RankAdd-PrevQ-RankAdd-PrevQ': {'accuracy': 0.8196749439151715, 'f1_micro': 0.8196749439151715, 'f1_macro': 0.7622133470792942, 'num_epoch': 65, 'total_epoch': 50, 'labeldiff': 0.032351187539945696, 'recall_0': 0.8470554351043659, 'precision_0': 0.8734058174258797, 'f1_0': 0.8600288365859107, 'labelratio_0': 0.030169689502612146, 'recall_1': 0.8215467916415465, 'precision_1': 0.8042381657628365, 'f1_1': 0.8128003421227366, 'labelratio_1': 0.021521766331858358, 'recall_2': 0.6423238566131027, 'precision_2': 0.5877216793340572, 'f1_2': 0.6138108625292353, 'labelratio_2': 0.09290482076637825, 'searchspace': 1, 'pe': '-', 'atnl': 1}})\n"
     ]
    }
   ],
   "source": [
    "print(resultdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b33f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dataname != \"emailEu_0\":\n",
    "evallist = [\"f1_micro\", \"f1_macro\"]\n",
    "# else:\n",
    "#     evallist = [\"f1_micro\", \"f1_macro\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1efe040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputname = \"PEResult_{}.txt\".format(dataname)\n",
    "with open(outputname, \"w\") as f:\n",
    "    line = \"Model,AttV,AggV,AttE,AggE,atnl,pe,\" + \",\".join(evallist) + \",searchspace,epoch\"\n",
    "    f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c008023",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in resultdict:\n",
    "    modelname = k\n",
    "    tmp = modelname.split(\"-\")\n",
    "    \n",
    "    if len(tmp) == 1:\n",
    "        model = tmp[0]\n",
    "        attV, aggV, attE, aggE = \"-\", \"-\", \"-\", \"-\"\n",
    "    else:\n",
    "        model, attV, aggV, attE, aggE = tmp\n",
    "    \n",
    "    line = [model, attV, aggV, attE, aggE, str(resultdict[k][\"atnl\"]), str(resultdict[k][\"pe\"])] + [str(resultdict[k][e]) for e in evallist] + [str(resultdict[k][\"searchspace\"]), str(resultdict[k][\"num_epoch\"])]\n",
    "    line = \",\".join(line)\n",
    "    with open(outputname, \"a\") as f:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68289e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emailEnron_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AttV</th>\n",
       "      <th>AggV</th>\n",
       "      <th>AttE</th>\n",
       "      <th>AggE</th>\n",
       "      <th>atnl</th>\n",
       "      <th>pe</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>searchspace</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformer</td>\n",
       "      <td>RankAdd</td>\n",
       "      <td>PrevQ</td>\n",
       "      <td>RankAdd</td>\n",
       "      <td>PrevQ</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>0.819675</td>\n",
       "      <td>0.762213</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model     AttV   AggV     AttE   AggE  atnl pe  f1_micro  f1_macro  \\\n",
       "0  transformer  RankAdd  PrevQ  RankAdd  PrevQ     1  -  0.819675  0.762213   \n",
       "\n",
       "   searchspace  epoch  \n",
       "0            1     65  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataname)\n",
    "d = pd.read_csv(outputname)\n",
    "# print(d)\n",
    "d = d.sort_values(by=[\"f1_micro\"], ascending=False)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eca7c4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer-RankQ-PrevQ-pure-PrevQ\n",
      "../results_v2/DBLP2_0/rw/transformer-RankQ-PrevQ-pure-PrevQ_atnl1_nl2_sm_snl1/hd_64_od_128_bs_64_lr_0.001_ni_4_sp_-1/\n",
      "--------------\n",
      "transformer-ShawRE-PrevQ-pure-PrevQ\n",
      "../results_v2/DBLP2_0/rw/transformer-ShawRE-PrevQ-pure-PrevQ_atnl1_nl1_sm_snl1/hd_64_od_128_bs_32_lr_0.001_ni_4_sp_-1_pe_KPRW/\n",
      "--------------\n",
      "transformer-ITRE-PrevQ-pure-PrevQ\n",
      "../results_v2/DBLP2_0/rw/transformer-ITRE-PrevQ-pure-PrevQ_atnl1_nl1_sm_snl1/hd_64_od_128_bs_32_lr_0.001_ni_4_sp_-1_pe_KD/\n",
      "--------------\n",
      "transformer-RankAdd-PrevQ-pure-PrevQ\n",
      "../results_v2/DBLP2_0/rw/transformer-RankAdd-PrevQ-pure-PrevQ_atnl1_nl2_sm_snl1/hd_64_od_128_bs_64_lr_0.001_ni_4_sp_-1/\n",
      "--------------\n",
      "transformer-pure-PrevQ-pure-PrevQ\n",
      "../results_v2/DBLP2_0/rw/transformer-pure-PrevQ-pure-PrevQ_atnl1_nl1_sm_snl1/hd_64_od_128_bs_64_lr_0.001_ni_4_sp_-1/\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for k, v in model2bestparam.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ec4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Full on Python 3.7 (GPU)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
